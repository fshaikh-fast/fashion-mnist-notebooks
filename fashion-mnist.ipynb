{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/fashion',one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUVAMP1FQDD9RUAw/UVD/B+dpEjJTR3YKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0800cf7f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pixels = data.train.images[9].reshape((28, 28))\n",
    "plt.imshow(pixels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What should be the optimal learning rate\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why batch size ? \n",
    "\n",
    "A convolutional neural network (CNN) doesn’t process its inputs one-at-a-time: to increase throughput, it will process the data in batches.\n",
    "\n",
    "For CNNs that are trained on images, for example, say your dataset is RGB (3-channel) images that are 256x256 pixels. A single image can be represented by a 3 x 256 x 256 matrix. If you set your batch size to be 10, that means you’re concatenating 10 images together into a 10 x 3 x 256 x 256 matrix.\n",
    "\n",
    "In practice, you’ll create batches of data that are randomly selected from your training set. This is the ‘stochastic’ part of stochastic gradient descent (SGD). During a single forward and backward pass of training, the network will update its parameters according to what’s in the batch. This is why the selection has to be random - if you feed in a batch of only dog images, the CNN will become a little more eager to classify images as dogs after that training iteration.\n",
    "\n",
    "Tuning the batch size is one of the aspects of getting training right - if your batch size is too small, then there will be a lot of variance within a batch, and your training loss curve will bounce around a lot. But if it’s too large, your GPU will run out of memory to hold it, or training will progress too slowly to see if it’s the optimization is diverging early on.\n",
    "\n",
    "I think you’ll also find the answers to this question helpful:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuitively, how does mini-batch size affect the performance of (stochastic) gradient descent?\n",
    "\n",
    "Algorithmically speaking, using larger mini-batches in SGD allows you to reduce the variance of your stochastic gradient updates (by taking the average of the gradients in the mini-batch), and this in turn allows you to take bigger step-sizes, which means the optimization algorithm will make progress faster. However, the amount of work done (in terms of number of gradient computations) to reach a certain accuracy in the objective will be the same: with a mini-batch size of n, the variance of the update direction will be reduced by a factor n, so the theory allows you to take step-sizes that are n times larger (see, e.g., [1, end of Section 4.2]), so that a single step will take you roughly to the same accuracy as n steps of SGD with a mini-batch size of 1.\n",
    "\n",
    "This sounds like great news since it suggests that taking very large mini-batches will converge just as quickly in terms of gradient computations as using a single example at a time, which is great because computing the gradient on a large mini-batch is trivial to parallelize (on a GPU, multiple GPUs or even many machines), while using a single example per iteration requires synchronization after each example, which makes parallelization much more challenging.\n",
    "\n",
    "So where's the catch? Well, even though we said that larger mini-batches allow you to use larger step-sizes, the step-size cannot exceed an algorithmic, problem-dependent upper bound which depends on the smoothness of the objective function (typically 1/L, where L is the Lipschitz constant of the \"full\" gradients), so that once you've reached this step-size, increasing the mini-batch size will no longer allow you to increase the step-size, which means the extra computation in computing more gradients will be wasted. As an aside, note that SGD with fixed mini-batch size typically needs smaller step-sizes near the optimum, and in that situation one could consider increasing the batch size instead of decreasing the step-sizes, for improved parallelism.\n",
    "\n",
    "In practice, especially in the case of deep learning with GPUs, larger mini-batches are very attractive computationally. In addition to easy parallelism across processors/machines, they can give much better throughput, for example by making use of efficient data reuse during back-propagation (e.g. doing one matrix-matrix multiply is much more efficient than doing many matrix-vector multiplies, since the latter likely needs to reload matrix data in registers more often), and by wasting less time in data communication round-trips. For these reasons it is quite common in practice to pick batch-sizes that fully leverage the GPU (e.g. until the memory is filled up), and just choose the largest step-size that works well in practice after a few quick trials. If the choice of step-size turns out to be guided by the 1/L (smoothness) constraint, then the variance of the updates will probably be lower than needed, but that's fine since it just means we’ll be able to keep the step-size constant for a longer period of time.\n",
    "\n",
    "Update (June 2017): Facebook managed to scale up this strategy, which they call “linear scaling rule”, to a mini-batch size of 8192 for training state-of-the-art CNNs on ImageNet (Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour). They achieved this by including an initial “warmup” phase to prevent optimization difficulties with large step-sizes in the first few epochs, and by ensuring minimal communication overhead.\n",
    "\n",
    "[1] [1606.04838] Optimization Methods for Large-Scale Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# why training in batches ? how many epochs ?\n",
    "for _ in range(1000):\n",
    "  batch_xs, batch_ys = data.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7889\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: data.test.images, y_: data.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
